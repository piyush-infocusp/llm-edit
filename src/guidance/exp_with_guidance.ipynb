{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate\n",
    "!pip install sentencepiece\n",
    "\n",
    "!pip install torch\n",
    "!pip install transformers==4.45\n",
    "!pip install guidance # work with transformers==4.45\n",
    "!pip install huggingface_hub\n",
    "\n",
    "!pip install gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "login(os.getenv(\"HF_ACCESS_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dd5a5ea31344159957743aa52aecf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/838 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a3db46c4414920835454d72c1acb1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/24.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1880357078dc467f8b5d36de1a698fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101742cf0fbe4531b92a9374aa703720",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500b19b118264217a158f87f55e92a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/241M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mguidance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[0;32m----> 2\u001b[0m gpt \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTransformers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgoogle/gemma-2-2b-it\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pf/lib/python3.9/site-packages/guidance/models/transformers/_transformers.py:615\u001b[0m, in \u001b[0;36mTransformers.__init__\u001b[0;34m(self, model, tokenizer, echo, compute_log_probs, chat_template, enable_backtrack, enable_ff_tokens, enable_monitoring, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    603\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    612\u001b[0m ):\n\u001b[1;32m    613\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a new Transformers model object that represents a model in a given state.\"\"\"\u001b[39;00m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m--> 615\u001b[0m         \u001b[43mTransformersEngine\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompute_log_probs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchat_template\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_backtrack\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_backtrack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_ff_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_ff_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m            \u001b[49m\u001b[43menable_monitoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_monitoring\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    625\u001b[0m         echo\u001b[38;5;241m=\u001b[39mecho,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/pf/lib/python3.9/site-packages/guidance/models/transformers/_transformers.py:406\u001b[0m, in \u001b[0;36mTransformersEngine.__init__\u001b[0;34m(self, model, tokenizer, compute_log_probs, chat_template, enable_backtrack, enable_ff_tokens, enable_monitoring, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/pf/lib/python3.9/site-packages/guidance/models/transformers/_transformers.py:452\u001b[0m, in \u001b[0;36mTransformersEngine._model\u001b[0;34m(self, model, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_transformers:\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    450\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install transformers with `pip install transformers` in order to use guidance.models.Transformers!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    451\u001b[0m         )\n\u001b[0;32m--> 452\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtransformers_package\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/pf/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/pf/lib/python3.9/site-packages/transformers/modeling_utils.py:3880\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3874\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_autoset_attn_implementation(\n\u001b[1;32m   3875\u001b[0m     config, use_flash_attention_2\u001b[38;5;241m=\u001b[39muse_flash_attention_2, torch_dtype\u001b[38;5;241m=\u001b[39mtorch_dtype, device_map\u001b[38;5;241m=\u001b[39mdevice_map\n\u001b[1;32m   3876\u001b[0m )\n\u001b[1;32m   3878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ContextManagers(init_contexts):\n\u001b[1;32m   3879\u001b[0m     \u001b[38;5;66;03m# Let's make sure we don't run the init function of buffer modules\u001b[39;00m\n\u001b[0;32m-> 3880\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3882\u001b[0m \u001b[38;5;66;03m# make sure we use the model's config since the __init__ call might have copied it\u001b[39;00m\n\u001b[1;32m   3883\u001b[0m config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'device'"
     ]
    }
   ],
   "source": [
    "from guidance import models\n",
    "gpt = models.Transformers('google/gemma-2-2b-it', device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jinja2 import Environment, FileSystemLoader\n",
    "def load_template(template_dir, template_name):\n",
    "    # Create a Jinja environment\n",
    "    env = Environment(loader=FileSystemLoader(template_dir))\n",
    "\n",
    "    # Load a specific template\n",
    "    template = env.get_template(template_name)\n",
    "\n",
    "    # Print the output\n",
    "    return template\n",
    "\n",
    "instruction =  \"Remove points of view:\" \n",
    "doc = \"\"\"the term \"\"deposit of faith\"\" refers to the entirety of jesus christ's divine revelation, and is passed forward to successive generations in two different forms, sacred scripture (the bible) and sacred tradition (apostolic succession).\"\"\"\n",
    "\n",
    "temp = load_template(\"/home/piyush.sar/Projects/LegalSifter/llm-edit/src/templates\", \"prompt simplified.jinja\")\n",
    "\n",
    "prompt = temp.render(text=doc, instructions=[{\"id\": 1, \"task\": \"Remove points of view:\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>Please tag each word in the input with PER, ORG, LOC, or nothing\n",
       "---\n",
       "Input: John worked at Apple.\n",
       "Output:\n",
       "John: PER\n",
       "worked: \n",
       "at: \n",
       "Apple: ORG\n",
       ".: \n",
       "---\n",
       "Input: Julia never went to Morocco in her life!!\n",
       "Output:\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>Julia</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> LOC</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>never</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> ORG</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>went</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>to</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>Morocco</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> LOC</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>in</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>her</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> LOC</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span></pre>"
      ],
      "text/plain": [
       "<guidance.models.transformers._transformers.Transformers at 0x7d4592970a90>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get the top k probabilities for the tokens [2, 5958, 5886, 1853, 2204, 575, 573, 3772, 675, 12504, 235269, 153235, 235269, 25689, 235269, 689, 4285, 108, 3976, 108, 3678, 235292, 3350, 6800, 696, 9865, 235265, 108, 6140, 235292, 108, 6726, 235292, 12504, 108, 64823, 235292, 235248, 108, 482, 235292, 235248, 108, 22732, 235292, 153235, 108, 5672, 235248, 108, 3976, 108, 3678, 235292, 31918, 2447, 3815, 577, 52237, 575, 1070, 1913, 2024, 108, 6140, 235292, 108, 53270, 235292, 25689, 108, 29422, 235292, 153235, 108, 36626, 235292, 235248, 108, 511, 235292, 235248, 108, 147245, 235292, 25689, 108, 473, 235292, 235248, 108, 2794, 235292, 25689, 108]. Error: 'int' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE NER\n",
    "import guidance\n",
    "@guidance(stateless=True)\n",
    "def ner_instruction(lm, input):\n",
    "    lm += f'''\\\n",
    "    Please tag each word in the input with PER, ORG, LOC, or nothing\n",
    "    ---\n",
    "    Input: John worked at Apple.\n",
    "    Output:\n",
    "    John: PER\n",
    "    worked: \n",
    "    at: \n",
    "    Apple: ORG\n",
    "    .: \n",
    "    ---\n",
    "    Input: {input}\n",
    "    Output:\n",
    "    '''\n",
    "    return lm\n",
    "input = 'Julia never went to Morocco in her life!!'\n",
    "gpt + ner_instruction(input) + gen(stop='---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>Please tag each word in the input with PER, ORG, LOC, or nothing\n",
       "---\n",
       "Input: John worked at Apple.\n",
       "Output:\n",
       "John: PER\n",
       "worked: \n",
       "at: \n",
       "Apple: ORG\n",
       ".: \n",
       "---\n",
       "Input: Julia never went to Morocco in her life!!\n",
       "Output:\n",
       "</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>Julia:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> LOC</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "never:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> ORG</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "went:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>to:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>Morocco:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> LOC</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "in:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>her:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> LOC</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "life:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> ORG</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "!:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>!:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span></pre>"
      ],
      "text/plain": [
       "<guidance.models.transformers._transformers.Transformers at 0x7d4591a9e9d0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get the top k probabilities for the tokens [2, 5958, 5886, 1853, 2204, 575, 573, 3772, 675, 12504, 235269, 153235, 235269, 25689, 235269, 689, 4285, 108, 3976, 108, 3678, 235292, 3350, 6800, 696, 9865, 235265, 108, 6140, 235292, 108, 6726, 235292, 12504, 108, 64823, 235292, 235248, 108, 482, 235292, 235248, 108, 22732, 235292, 153235, 108, 5672, 235248, 108, 3976, 108, 3678, 235292, 31918, 2447, 3815, 577, 52237, 575, 1070, 1913, 2024, 108, 6140, 235292, 108, 53270, 235292, 25689, 108, 29422, 235292, 153235, 108, 36626, 235292, 235248, 108, 511, 235292, 235248, 108, 147245, 235292, 25689, 108, 473, 235292, 235248, 108, 2794, 235292, 25689, 108, 7641, 235292, 153235, 108, 39872, 235248, 108, 39872, 235248, 108]. Error: 'int' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE NER\n",
    "import re\n",
    "\n",
    "@guidance(stateless=True)\n",
    "def constrained_ner(lm, input):\n",
    "    # Split into words\n",
    "    words = [x for x in re.split('([^a-zA-Z0-9])', input) if x and not re.match('\\s', x)]\n",
    "    ret = ''\n",
    "    for x in words:\n",
    "        ret += x + ': ' + select(['PER', 'ORG', 'LOC', '']) + '\\n'\n",
    "    return lm + ret\n",
    "gpt + ner_instruction(input) + constrained_ner(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammer for insert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from guidance import gen, select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>Should I say &quot;Scott&quot;?\n",
       "</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>yes</span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>\n",
       "</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'>Scott</span></pre>"
      ],
      "text/plain": [
       "<guidance.models.transformers._transformers.Transformers at 0x7d4591839d60>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get the top k probabilities for the tokens [2, 15284, 590, 1931, 664, 23978, 27017, 108, 3276, 108, 23978]. Error: 'int' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "@guidance(stateless=False)\n",
    "def test(lm):\n",
    "    lm += 'Should I say \"Scott\"?\\n' + select(['yes', 'no'], name='answer') + '\\n'\n",
    "    if lm['answer'] == 'yes':\n",
    "        lm += 'Scott'\n",
    "    else:\n",
    "        lm += 'Not Scott'\n",
    "    return lm\n",
    "gpt + test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='margin: 0px; padding: 0px; vertical-align: middle; padding-left: 8px; margin-left: -8px; border-radius: 0px; border-left: 1px solid rgba(127, 127, 127, 0.2); white-space: pre-wrap; font-family: ColfaxAI, Arial; font-size: 15px; line-height: 23px;'><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'>Write a clear and enhanced version of the given text. Use the following guidelines for edits:\n",
       "\n",
       "1. **Add New Content**: Use `&lt;insert]&gt;[new content]&lt;/insert&gt;` to add examples or additional sentences where indicated. For instance:\n",
       "   - `&lt;insert&gt;For example, drinking water, eating a balanced diet, and avoiding processed foods are effective ways to improve nutrition.&lt;/insert&gt;`\n",
       "   \n",
       "2. **Remove Existing Content**: Use `&lt;insert&gt;[content to remove]&lt;/delete&gt;` to delete phrases or sentences where specified. For example:\n",
       "   - `&lt;delete&gt;good for overall well-being&lt;/delete&gt;`\n",
       "\n",
       "3. **Replace Content**: Combine **delete** and **insert** tags to replace a phrase with more detailed information. For example:\n",
       "   - `&lt;delete&gt;good for overall well-being&lt;/delete&gt;&lt;insert&gt;essential for improving immune function, energy levels, and mental clarity.&lt;/insert&gt;`\n",
       "\n",
       "4. **no edit associated with the task**: Use `&lt;noedit&gt;[Reason]&lt;noedit&gt;` to indicate that no edit is required for a specific task. For example:\n",
       "   - `&lt;noedit&gt;[No search text found]&lt;/noedit&gt;`\n",
       "\n",
       "5. If you want to insert newlines please do it withing &lt;insert&gt; tags. Ensure output doc is grounded onto the input doc.\n",
       "\n",
       "### Example:\n",
       "#### Tasks:\n",
       "- ID 1. Add examples of healthy eating habits to illustrate good nutrition.\n",
       "- ID 2. Replace &quot;good for overall well-being&quot; with a more detailed description.\n",
       "- ID 3. Add a concluding sentence emphasizing the importance of taking small, sustainable steps toward better nutrition.\n",
       "- ID 4. If the doc mentions about heart health, please add a point about LDL and HDL.\n",
       "\n",
       "#### Edits:\n",
       "Healthy eating is important for maintaining health. &lt;insert&gt;For example, drinking water, eating a balanced diet, and avoiding processed foods are effective ways to improve nutrition.&lt;/insert&gt; Nutrition is &lt;delete&gt;good for overall well-being&lt;/delete&gt;&lt;insert&gt;essential for improving immune function, energy levels, and mental clarity.&lt;/insert&gt; To start your journey to healthier eating, &lt;insert&gt;focus on small, achievable changes, such as swapping sugary snacks for fruits or adding more vegetables to your meals.&lt;/insert&gt;\n",
       "\n",
       "# Given:\n",
       "\n",
       "## Input Text:\n",
       "the term &quot;&quot;deposit of faith&quot;&quot; refers to the entirety of jesus christ&#x27;s divine revelation, and is passed forward to successive generations in two different forms, sacred scripture (the bible) and sacred tradition (apostolic succession).\n",
       "\n",
       "## Tasks:\n",
       "\n",
       "- ID 1: Remove points of view:\n",
       "\n",
       "\n",
       "# Enhanced Output:</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>the</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>term</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>&quot;&quot;deposit</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>of</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>faith&quot;&quot;</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>refers</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>to</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>the</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>entirety</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>of</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>jesus</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>christ&#x27;s</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>divine</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>revelation,</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>and</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>is</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>passed</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>forward</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>to</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>successive</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>generations</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>in</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>two</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>different</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>forms,</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>sacred</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>scripture</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>(the</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>bible)</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>and</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>sacred</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>tradition</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>(apostolic</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span><span style='background-color: rgba(0, 0, 255, 0.15); border-radius: 3ps;' title='0.0'>succession).</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'>&lt;insert&gt;</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>For</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> example</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>,</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> drinking</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> water</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>,</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> eating</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> a</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> balanced</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> diet</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>,</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> and</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> avoiding</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> processed</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> foods</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> are</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> effective</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> ways</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> to</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> improve</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'> nutrition</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>.&lt;/</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>insert</span><span style='background-color: rgba(0, 255, 0, 0.15); border-radius: 3ps;' title='0.0'>&gt;</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'>&lt;/insert&gt;</span><span style='background-color: rgba(255, 255, 255, 0.15); border-radius: 3ps;' title='0.0'> </span></pre>"
      ],
      "text/plain": [
       "<guidance.models.transformers._transformers.Transformers at 0x7d45929b18b0>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to get the top k probabilities for the tokens [2, 5559, 476, 3110, 578, 20085, 3797, 576, 573, 2764, 2793, 235265, 5362, 573, 2412, 17923, 604, 62791, 235292, 109, 235274, 235265, 5231, 2341, 1622, 13193, 95573, 5362, 100456, 8831, 235307, 32403, 1404, 3381, 77595, 8831, 65529, 577, 1843, 8944, 689, 5942, 26099, 1570, 11969, 235265, 1699, 5566, 235292, 108, 140, 235290, 100456, 8831, 235313, 1636, 3287, 235269, 16036, 2003, 235269, 12150, 476, 24748, 11652, 235269, 578, 39017, 23576, 16512, 708, 7017, 5742, 577, 4771, 24539, 7221, 8831, 65529, 108, 140, 108, 235284, 235265, 5231, 13681, 58368, 13193, 95573, 5362, 100456, 8831, 32403, 3312, 577, 6504, 77595, 4958, 65529, 577, 8958, 35070, 689, 26099, 1570, 10626, 235265, 1699, 3287, 235292, 108, 140, 235290, 100456, 4958, 235313, 8311, 604, 8691, 1578, 235290, 16978, 727, 4958, 65529, 109, 235304, 235265, 5231, 32928, 13193, 95573, 69196, 5231, 4958, 688, 578, 5231, 8831, 688, 16323, 577, 7919, 476, 20911, 675, 978, 11352, 2113, 235265, 1699, 3287, 235292, 108, 140, 235290, 100456, 4958, 235313, 8311, 604, 8691, 1578, 235290, 16978, 727, 4958, 2577, 8831, 235313, 53763, 604, 19031, 24091, 1411, 235269, 4134, 5902, 235269, 578, 9663, 34935, 7221, 8831, 65529, 109, 235310, 235265, 5231, 956, 9387, 7059, 675, 573, 6911, 95573, 5362, 100456, 956, 5427, 32403, 27257, 81070, 956, 5427, 65529, 577, 12181, 674, 793, 9387, 603, 3690, 604, 476, 3724, 6911, 235265, 1699, 3287, 235292, 108, 140, 235290, 100456, 956, 5427, 32403, 1294, 4544, 2793, 1942, 77595, 956, 5427, 65529, 109, 235308, 235265, 1927, 692, 1938, 577, 14455, 888, 5448, 3743, 749, 665, 675, 574, 968, 8831, 235313, 16323, 235265, 45409, 5033, 2865, 603, 57236, 10401, 573, 3772, 2865, 235265, 109, 6176, 13686, 235292, 108, 3308, 63960, 235292, 108, 235290, 4781, 235248, 235274, 235265, 4463, 8944, 576, 9606, 12150, 22523, 577, 33634, 1426, 24539, 235265, 108, 235290, 4781, 235248, 235284, 235265, 45965, 664, 8311, 604, 8691, 1578, 235290, 16978, 235281, 675, 476, 978, 11352, 5966, 235265, 108, 235290, 4781, 235248, 235304, 235265, 4463, 476, 75804, 13060, 98644, 573, 9156, 576, 4998, 2301, 235269, 19496, 7161, 8906, 2525, 24539, 235265, 108, 235290, 4781, 235248, 235310, 235265, 1927, 573, 2865, 41986, 1105, 3760, 2962, 235269, 3743, 1843, 476, 2377, 1105, 123478, 578, 137598, 235265, 109, 3308, 176757, 235292, 108, 67484, 12150, 603, 2845, 604, 22522, 2962, 235265, 968, 8831, 235313, 1636, 3287, 235269, 16036, 2003, 235269, 12150, 476, 24748, 11652, 235269, 578, 39017, 23576, 16512, 708, 7017, 5742, 577, 4771, 24539, 7221, 8831, 235313, 37792, 603, 968, 4958, 235313, 8311, 604, 8691, 1578, 235290, 16978, 727, 4958, 2577, 8831, 235313, 53763, 604, 19031, 24091, 1411, 235269, 4134, 5902, 235269, 578, 9663, 34935, 7221, 8831, 235313, 1887, 2238, 861, 10734, 577, 54578, 12150, 235269, 968, 8831, 235313, 17362, 611, 2301, 235269, 116214, 4559, 235269, 1582, 685, 109330, 174278, 38858, 604, 16803, 689, 10480, 978, 19574, 577, 861, 21305, 7221, 8831, 235313, 109, 235345, 22546, 235292, 109, 1620, 11438, 4820, 235292, 108, 1175, 5168, 4973, 58983, 576, 8278, 1581, 20604, 577, 573, 71893, 576, 55697, 39567, 235303, 235256, 21537, 50646, 235269, 578, 603, 7206, 4830, 577, 38521, 24714, 575, 1378, 2167, 7539, 235269, 26156, 97777, 591, 1175, 53092, 235275, 578, 26156, 12336, 591, 235250, 105196, 37209, 846, 109, 1620, 63960, 235292, 109, 235290, 4781, 235248, 235274, 235292, 17691, 3782, 576, 2116, 235292, 110, 235345, 71439, 16230, 235292, 1175, 5168, 4973, 58983, 576, 8278, 1581, 20604, 577, 573, 71893, 576, 55697, 39567, 235303, 235256, 21537, 50646, 235269, 578, 603, 7206, 4830, 577, 38521, 24714, 575, 1378, 2167, 7539, 235269, 26156, 97777, 591, 1175, 53092, 235275, 578, 26156, 12336, 591, 235250, 105196, 37209, 846, 235322, 8831, 235313, 1636, 3287, 235269, 16036, 2003, 235269, 12150, 476, 24748, 11652, 235269, 578, 39017, 23576, 16512, 708, 7017, 5742, 577, 4771, 24539, 7221, 8831, 3119, 8831, 235313, 235248]. Error: 'int' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "\n",
    "words = doc.split()\n",
    "\n",
    "@guidance(stateless=False)\n",
    "def constrained_ner(lm, words):\n",
    "    # Split into words\n",
    "    for i,x in enumerate(words):\n",
    "        op = select(['<insert>', x],name=x)\n",
    "        lm += op\n",
    "        if lm[x] == '<insert>':\n",
    "            lm += gen(max_tokens=100, stop='</insert>')\n",
    "            lm += '</insert>'\n",
    "            lm += x\n",
    "        else:\n",
    "            if i == len(words) - 1:\n",
    "                lm += '<insert>'\n",
    "                lm += gen(max_tokens=100)\n",
    "                lm += '</insert>'\n",
    "            \n",
    "        lm += ' '    \n",
    "    return lm\n",
    "\n",
    "gpt + prompt + constrained_ner(words)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
